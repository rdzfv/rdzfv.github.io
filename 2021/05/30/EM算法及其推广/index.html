<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="xyy">





<title>《统计机器学习》读书笔记 · EM算法及其推广 | xyy爱吃番茄</title>



    <link rel="icon" href="https://qiniu.xuyuyan.cn/XYY.png">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 5.4.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">xyy爱吃番茄！(个人分享)</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于我</a>
                
                    <a class="menu-item" href="/friends">友链</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">xyy爱吃番茄！(个人分享)</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于我</a>
                
                    <a class="menu-item" href="/friends">友链</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">《统计机器学习》读书笔记 · EM算法及其推广</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">xyy</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">五月 30, 2021&nbsp;&nbsp;21:40:43</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《统计学习方法》读书笔记</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>《统计学习方法》EM 算法的部分读书笔记</p>
<span id="more"></span>

<h3 id="1-引入-·-三硬币模型"><a href="#1-引入-·-三硬币模型" class="headerlink" title="1. 引入 · 三硬币模型"></a>1. 引入 · 三硬币模型</h3><p>​    假设有三枚硬币，分别记作A、B、C。这三枚硬币正面朝上的概率分别为 $\pi$、$p$ 和 $q$。进行如下掷硬币实验：先掷硬币 A，如果 A 为正面则下一个掷 B，反面掷 C；以第二枚硬币的结果为最终结果。进行独立重复实验。</p>
<p>​    我们将独立重复实验得到的结果记作 “<font style="background: #F9EDA6">观测结果</font>”；将每次硬币 A 的结果记为 “<font style="background: #F9EDA6">不可观测数据（隐变量）</font>”。假设我们只能知道观测结果，如何去估计隐变量？这就是 EM 算法解决的问题。（<font style="background: #FBD4D0">用于含有隐变量的概率模型参数的极大似然估计</font>）</p>
<br>

<h3 id="2-EM-算法的导出"><a href="#2-EM-算法的导出" class="headerlink" title="2. EM 算法的导出"></a>2. EM 算法的导出</h3><blockquote>
<p>算法：<font style="background: #d4e9d6">（EM算法）</font></p>
<p>输入：模型参数 $\theta$</p>
<ol>
<li><p>选择参数的初值 $\theta^{(0)}$，开始迭代。</p>
</li>
<li><p>E 步（求期望）：记 $\theta^{(i)}$ 为第 i 次迭代参数 $\theta$ 的估计值，在第 i+1 次迭代的 E 步，计算：</p>
<p>$Q(\theta,\theta^{(i)})=E_Z[logP(Y,Z|\theta)|Y, \theta^{(i)}]$</p>
<p>$=\sum_ZlogP(Y,Z|\theta)P(Z|Y,\theta^{(i)})$</p>
<p>此处，$P(Z|Y,\theta^{(i)})$ 是给定观测数据 Y 和当前的参数估计 $\theta^{(i)}$ 下隐变量数据 Z 的条件概率分布。</p>
</li>
<li><p>M 步（求极大）：求使 $Q(\theta,\theta^{(i)})$ 极大化的 $\theta$，确定第 i+1 次迭代的参数的估计值 $\theta^{(i+1)}$ </p>
<p>$\theta^{(i+1)}=arg\ max_{\theta}Q(\theta, \theta^{(i)})$</p>
</li>
<li><p>重复第二步和第三步，直到收敛。</p>
</li>
</ol>
</blockquote>
<p>接下来对 EM 算法进行推导：</p>
<p>我们的目标是<font style="background: #F9EDA6">极大化观测数据 Y 关于参数 $\theta$ 的对数似然函数</font>，也就是 $L(\theta)=log P(Y|\theta)$</p>
<img src="https://qiniu.xuyuyan.cn/image-20210530150836548.png" alt="image-20210530150836548" style="zoom:33%;" /> 

<p>将上面的不等式进行整理：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530151122965.png" alt="image-20210530151122965" style="zoom:33%;" />

<p>为了使 $L(\theta)$ 有尽可能大的增长，选择 $\theta^{(i+1)}$ 使 $B(\theta, \theta^{(i)})$ 达到极大：$\theta^{(i+1)}=arg\ max_{\theta}B(\theta, \theta^{(i)})$</p>
<p>对这个表达式进行化简：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530155612639.png" alt="image-20210530155612639" style="zoom:33%;" />

<p>EM 算法就是<font style="background: #F9EDA6">通过不断对 Q 函数（下界）求极大，逼近求解对数似然函数极大化</font>。</p>
<p>将上述算法步骤进行总结：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530164519762.png" alt="image-20210530164519762" style="zoom:33%;" />

<br>

<h3 id="3-EM-算法的收敛性"><a href="#3-EM-算法的收敛性" class="headerlink" title="3. EM 算法的收敛性"></a>3. EM 算法的收敛性</h3><p>​    在第二章中，我们并未对以下两个问题进行分析：</p>
<ol>
<li><p><font style="background: #FBD4D0">EM 算法的估计序列是否收敛？</font></p>
</li>
<li><p><font style="background: #FBD4D0">如果收敛，是否收敛到全局最大值或者局部最大值？</font></p>
<p>我们将通过以下两个定理进行介绍。</p>
</li>
</ol>
<h4 id="3-1-递增性"><a href="#3-1-递增性" class="headerlink" title="3.1 递增性"></a>3.1 递增性</h4><blockquote>
<p>定理：设 $P(Y|\theta)$ 为观测数据的似然函数，$\theta^{(i)}$ 为 EM 算法得到的参数估计序列，$P(Y|\theta^{(i)})$ 为对应的似然函数序列，则 <font style="background: #d4e9d6">$P(Y|\theta^{(i)})$ 是单调递增的</font>。</p>
</blockquote>
<p>接下来我们进行证明：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530191432219.png" alt="image-20210530191432219" style="zoom:33%;" />

<p>若要证明 $P(Y|\theta)$ 是单调递增的，只需证明上式大于等于 0。</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530191902761.png" alt="image-20210530191902761" style="zoom:33%;" />

<p>至此， $P(Y|\theta)$ 是单调递增得证。</p>
<h4 id="3-2-收敛到极大值"><a href="#3-2-收敛到极大值" class="headerlink" title="3.2 收敛到极大值"></a>3.2 收敛到极大值</h4><blockquote>
<p>定理：设 $L(\theta)=logP(Y|\theta)$ 为观测数据的对数似然函数，$\theta^{(i)}$ 为 EM 算法得到的参数估计序列，$L(\theta^{(i)})$ 为对应的对数似然函数序列。</p>
<ol>
<li><font style="background: #d4e9d6">如果 $P(Y|\theta)$ 有上界，则 $L(\theta^{(i)})=logP(Y|\theta^{(i)})$ 收敛到某一值 $L^*$</font></li>
</ol>
</blockquote>
<p>由 $L(\theta)=logP(Y|\theta^{(i)})$ 的单调性及 $P(Y|\theta)$ 的有界性可以立即得到。</p>
<br>

<h3 id="4-EM-算法在高斯混合模型学习中的应用"><a href="#4-EM-算法在高斯混合模型学习中的应用" class="headerlink" title="4. EM 算法在高斯混合模型学习中的应用"></a>4. EM 算法在高斯混合模型学习中的应用</h3><h4 id="4-1-高斯分布"><a href="#4-1-高斯分布" class="headerlink" title="4.1 高斯分布"></a>4.1 高斯分布</h4><p>先简单介绍一下<font style="background: #d4e9d6">高斯分布</font></p>
<p>$\phi(y|\theta)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$</p>
<p>其中，$\mu$ 决定分布的位置；$\sigma^2$ 为方差，决定分布的幅度。</p>
<h4 id="4-2-高斯混合模型"><a href="#4-2-高斯混合模型" class="headerlink" title="4.2 高斯混合模型"></a>4.2 高斯混合模型</h4><p>高斯混合模型可以理解为<font style="background: #F9EDA6">由多个高斯分布叠加得到</font>，具有如下概率分布：</p>
<p>$P(y|\theta)=\sum_{k=1}^K\alpha_k\phi(y|\theta_k)$</p>
<p>其中 K 为 K 个叠加的高斯模型，$\alpha_k$ 为每个高斯模型的权重，$\phi(y|\theta_k)$ 为每个高斯模型。</p>
<h4 id="4-3-高斯混合模型参数估计的-EM-算法"><a href="#4-3-高斯混合模型参数估计的-EM-算法" class="headerlink" title="4.3 高斯混合模型参数估计的 EM 算法"></a>4.3 高斯混合模型参数估计的 EM 算法</h4><ul>
<li><p><font style="background: #CCE0F1">步骤一：明确隐变量 </font></p>
<p>设想观测数据 $y_j$ 的产生方式为：首先依据概率 $\alpha_k$ 选择 k 个高斯分布模型 $\phi(y|\theta_k)$；然后依第 k 个分模型的概率分布 $\phi(y|\theta_k)$ 生成观测数据 $y_j$。</p>
<p>其中，反映<font style="background: #F9EDA6">观测数据 $y_j$ 来自第 k 个分模型的数据是未知的，记作隐变量 $\gamma_{jk}$</font>。</p>
<p>$\gamma_{jk}=\begin{cases} 1 &amp;\text{第 j 个观测来自第 k 个模型} \\ 0 &amp;\text{否则} \end{cases}$ </p>
<p>通过观测数据 $y_j$ 和未观测数据 $\gamma_{jk}$，得到完全数据 $(y_j,\gamma_{j1},\gamma_{j2},…,\gamma_{jK})$</p>
<p>因此可以写出完全数据的<font style="background: #F9EDA6">似然函数</font>：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530200004997.png" alt="image-20210530200004997" style="zoom:33%;" />

<p>令 $n_k=\sum_{j=1}^N\gamma_{jk}$ 可得：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530200754651.png" alt="image-20210530200754651" style="zoom:33%;" />

<p>则完全数据的<font style="background: #F9EDA6">对数似然函数</font>为：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530202113984.png" alt="image-20210530202113984" style="zoom:33%;" /></li>
<li><p><font style="background: #CCE0F1">步骤二：（E）确定 Q 函数</font></p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530203611888.png" alt="image-20210530203611888" style="zoom:33%;" />

<p>此处需要<font style="background: #F9EDA6">计算 $E(\gamma_{jk},\theta)$</font>，记作 $\hat{\gamma_{jk}}$</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530204919283.png" alt="image-20210530204919283" style="zoom:33%;" /></li>
<li><p><font style="background: #CCE0F1">步骤三：（M）迭代求 Q 函数对 $\theta$ 的最大值（即求新一轮迭代的参数）</font></p>
<p>求 Q 函数的极大值，仅需<font style="background: #F9EDA6">对各参数（$\mu_k$，$\sigma_k^2$）求偏导并令其为 0</font>（拉格朗日参数法）</p>
<p>求 $\hat{\alpha_k}$ 是在 $\sum_{k=1}^K\alpha_k=1$ 下求偏导数并令其为 0（拉格朗日参数法）</p>
<p>可以得到如下结果</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530205311712.png" alt="image-20210530205311712" style="zoom:60%;" /></li>
</ul>
<p><font style="background: #F9EDA6">重复步骤二和步骤三，直到对数似然函数值不再有明显的变化。</font></p>
<h4 id="4-5-高斯混合模型参数估计-EM-算法总结"><a href="#4-5-高斯混合模型参数估计-EM-算法总结" class="headerlink" title="4.5 高斯混合模型参数估计 EM 算法总结"></a>4.5 高斯混合模型参数估计 EM 算法总结</h4><blockquote>
<p>输入：观测数据 $y_1$，$y_2$，…，$y_N$；高斯混合模型</p>
<p>输出：高斯混合模型参数</p>
<ol>
<li><p>取参数的初始值开始迭代</p>
</li>
<li><p>E 步：依据当前参数模型，计算分模型 k 对观测数据 $y_j$ 的响应度</p>
<p>$\hat{\gamma_{jk}}=\frac{\alpha_k\phi(y_j|\theta_k)}{\sum_{k=1}^K\alpha_k\phi(y_j|\theta_k)}$</p>
</li>
<li><p>M 步：计算新一轮迭代的模型参数</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210530205311712.png" alt="image-20210530205311712" style="zoom:60%;" /></li>
<li><p>重复步骤（2）和（3），直至收敛</p>
</li>
</ol>
</blockquote>
<br>

<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><p>本章主要介绍了 EM 算法，其本质就是<font style="background: #FBD4D0">通过不断迭代参数逼近似然函数的极大值</font></p>
<p>在第二章我们<font style="background: #FBD4D0">介绍了 EM 算法</font>，EM 算法顾名思义分为两步：</p>
<ol>
<li><p>E 步，求 Q 函数的期望（对数似然函数的期望）。</p>
</li>
<li><p>M 步，求使 Q 函数极大化的参数，确定下一次迭代的参数的估计值</p>
<p>$\theta^{(i+1)}=arg\ max_{\theta}Q(\theta,\theta^{(i)})$</p>
</li>
</ol>
<p>在第三章我们<font style="background: #FBD4D0">对 EM 算法进行了推导</font>：</p>
<ol>
<li>我们的目的是极大化对数似然函数 $L(\theta)$，因此找到对数似然函数的下限 $B(\theta,\theta^{(i)})$ ,将待解决的问题转换为 “寻找合适的参数使 $B(\theta,\theta^{(i)})$ 极大”。</li>
<li>通过对 $B(\theta,\theta^{(i)})$ 进行化简，我们可以得到 Q 函数，因此问题转化为 “寻找合适的参数使 Q 函数极大”，并且极大值为下一次迭代的参数。</li>
<li>使用新的参数重新计算 Q 函数，并继续求极大，直至收敛。</li>
</ol>
<p>在第四章我们<font style="background: #FBD4D0">证明了 </font>EM 算法得到的似然函数关于 $\theta^{(i)}$ 单调递增且有界。因此<font style="background: #FBD4D0">似然函数 $L(\theta)$ 收敛有上界</font>，因此 EM 算法在理论上可行。</p>
<p>在第五章我们<font style="background: #FBD4D0">介绍了 EM 算法在解决高斯混合模型中的应用</font>，主要分为三步：</p>
<ol>
<li><p>取参数初始值开始迭代</p>
</li>
<li><p>E 步：计算对数似然函数的期望</p>
<p>特别地，需要计算分模型 k 对观测数据 $y_k$ 的响应度（当前模型参属下第 j 个观测数据来自第 k 个分模型的概率）</p>
</li>
<li><p>M 步：计算新一轮的模型参数</p>
</li>
<li><p>重复第二步和第三步，直至收敛</p>
</li>
</ol>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>xyy</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://www.xuyuyan.cn/2021/05/30/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/">http://www.xuyuyan.cn/2021/05/30/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/</a></span>
                    </p>
                
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"># 机器学习</a>
                    
                        <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"># 统计学习方法</a>
                    
                        <a href="/tags/EM-%E7%AE%97%E6%B3%95/"># EM 算法</a>
                    
                        <a href="/tags/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/"># 高斯分布</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2021/06/24/public/webpushr-sw/"></a>
            
            
            <a class="next" rel="next" href="/2021/05/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/">《统计学习方法》读书笔记 · 提升方法</a>
            
        </section>


    </article>
</div>


    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="//unpkg.com/gitalk/dist/gitalk.css">
<script src="//unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
      var gitalk = new Gitalk({
        clientID: '4283629b368b1cf98f81',
        clientSecret: '8bb6ce27010c0db8286e943f3765aeae1757de4d',
        repo: 'xyyBlog',
        owner: 'rdzfv',
        admin: 'rdzfv',
        id: md5(location.pathname),      
        labels: 'Gitalk'.split(',').filter(l => l),
        perPage: 10,
        pagerDirection: 'last',
        createIssueManually: true,
        distractionFreeMode: true
      })
      gitalk.render('gitalk-container')
</script>



        </div>
        <footer id="footer" class="footer">
   <div class="copyright">
    <div style="position:fixed;left:8%;bottom:5%;">
        <div id="webpushr-subscription-button" data-button-text="订阅本站" data-subscriber-count-text="人已订阅" data-background-color="#000000"></div>
    </div>
    <div style="display:inline-block;">
        <div> <a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" style="text-decoration: none;color: black;" >浙ICP备19012712号</a> </div>
        <span>© xyy | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
