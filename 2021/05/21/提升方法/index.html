<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="xyy">





<title>《统计学习方法》读书笔记 · 提升方法 | xyy爱吃番茄（个人分享）</title>



    <link rel="icon" href="https://qiniu.xuyuyan.cn/XYY.png">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 5.4.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">xyy爱吃番茄！(个人分享)</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于我</a>
                
                    <a class="menu-item" href="/friends">友链</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">xyy爱吃番茄！(个人分享)</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">文章</a>
                
                    <a class="menu-item" href="/category">分类</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于我</a>
                
                    <a class="menu-item" href="/friends">友链</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">《统计学习方法》读书笔记 · 提升方法</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">xyy</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">五月 21, 2021&nbsp;&nbsp;18:12:57</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《统计学习方法》读书笔记</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>《统计学习方法》读书笔记提升方法部分</p>
<span id="more"></span>

<h3 id="1-提升方法的基本思路"><a href="#1-提升方法的基本思路" class="headerlink" title="1. 提升方法的基本思路"></a>1. 提升方法的基本思路</h3><p>首先介绍两个概念：<code>强可学习</code> 和 <code>弱可学习</code></p>
<p>强可学习就是，存在一个多项式的学习算法可以进行学习，并且正确率很高；弱可学习就是，学习的正确率仅比随机猜测略好。</p>
<p>一般来说，得到一个弱可学习的算法要比得到一个强可学习的算法要简单的多。那么，我们能否通过若弱可学习算法来得到强可学习算法？（这个研究问题就是我们说的提升方法）</p>
<p>对于 <font style="background: #F9EDA6">提升方法</font>来说，我们需要解决两个问题：</p>
<ul>
<li>在每一轮如何改变训练数据的权值或概率分布</li>
<li>如何将弱分类器组合成一个强分类器</li>
</ul>
<p>对于问题一，AdaBoost 的做法是， <font style="background: #F9EDA6">提高那些被前一轮分类器错误分类样本的权值</font>。也就是希望之后的分类器更加关注之前出错的样本。</p>
<p>对于问题二，AdaBoost 采取 <font style="background: #F9EDA6">加权多数表决</font>的方法，加大分类误差率小的弱分类器的权值。</p>
<br>

<h3 id="2-前向分步算法"><a href="#2-前向分步算法" class="headerlink" title="2. 前向分步算法"></a>2. 前向分步算法</h3><p>假设<font style="background: #d4e9d6">模型为 $f(x)=\sum_{m=1}^M\alpha_mG_m(x)$。$G_m(x)$ 为基函数</font>。</p>
<p>前向分步算法的思路是：因为学习的是加法模型，如果可以<font style="background: #F9EDA6">从前往后，每一步只学习一个基函数及其系数，逐步逼近目标函数</font>。就可以简化优化的复杂度。</p>
<img src="https://qiniu.xuyuyan.cn/image-20210521101454835.png" alt="image-20210521101454835" style="zoom:45%;" />

<p>将 $f(x)=f_{m-1}(x_i)+\alpha G(x_i)$ 带入损失函数 $loss=exp[-y_if(x)]$ 得到：</p>
<p><font style="background: #d4e9d6">$Loss=arg\ min_{\alpha,G} \sum_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\alpha G(x_i))]$</font></p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521102137486.png" alt="image-20210521102137486" style="zoom:35%;" />

<p>得到 $G$ 的最优解因为 $G_m^*=arg\ min_a \sum_i \overline{w_{m_i}}[y_i\neq G(x_i)]$</p>
<p>接下来求 $\alpha$ 的最优解：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521104609015.png" alt="image-20210521104609015" style="zoom:40%;" />

<p>至此我们得到了参数 $G$ 和 $\alpha$ </p>
<p>更新 $f_m(x)=f_{m-1}(x)+\alpha G(x)$</p>
<p>得到加法模型 $f(x)=f_M(x)=\sum_{i=1}^M\alpha_mG(x)$</p>
<blockquote>
<p><font style="background: #d4e9d6">算法（前向分步算法）</font>：</p>
<p>输入：训练数据集 $T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中 $x_i \in R^n,y_i \in {-1,+1}$；</p>
<p>输出：加法模型 $f(x)$</p>
<ol>
<li><p>初始化 $f_0(x)=0$</p>
</li>
<li><p>对 $m=1,2,…,M$</p>
<ul>
<li><p>极小化损失函数：$Loss=arg\ min_{\alpha,G} \sum_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\alpha G(x_i))]$</p>
<p>解得参数 $G$ 和 $\alpha$</p>
</li>
<li><p>更新 $f_m(x)=f_{m-1}(x)+\alpha G(x)$</p>
</li>
</ul>
</li>
<li><p>得到加法模型 $f(x)=f_M(x)=\sum_{i=1}^M\alpha_mG(x)$</p>
</li>
</ol>
<p>这样，前向分步算法<font style="background: #FBD4D0">将 “同时求解从 m = 1 到 M 所有参数的优化问题” 简化为 “逐次求解各个参数的优化问题” </font></p>
</blockquote>
<br>

<h3 id="3-AdaBoost-算法"><a href="#3-AdaBoost-算法" class="headerlink" title="3. AdaBoost 算法"></a>3. AdaBoost 算法</h3><p>AdaBoost 算法是一个非常具有代表性的提升方法。从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成一个强分类器。</p>
<blockquote>
<p><font style="background: #d4e9d6">算法（AdaBoost）</font>：</p>
<p>输入：训练数据集 $T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中 $x_i \in R^n,y_i \in {-1,+1}$；弱学习算法</p>
<p>输出：最终分类器 $G(x)$</p>
<ol>
<li><p>初始化训练数据的权值分布</p>
<p>$D_1=(w_{11},…,w_{1i},…,w_{1N}),w_{1i}=\frac{1}{N},i=1,2,…,N$</p>
</li>
<li><p>对 $m=1,2,…,M$ （不同分类器）</p>
<ul>
<li><p>使用权值分布 $D_m$ 的训练数据集学习，得到基本分类器 $G_m(x):\chi \rightarrow {-1,+1}$</p>
</li>
<li><p>计算 $G_m(x)$ 在训练数据集上的分类误差率 $e_m=\sum_{i=1}^NP(G_m(x_i)\neq y_i)=\sum_{i=1}^Nw_{mi}I(G_m(x_i)\neq y_i)$</p>
<p>（将分类错误的样本对应的权值求和）</p>
</li>
<li><p>计算 $G_m(x)$ 的系数 $\alpha_m=\frac{1}{2}ln\frac{1-e_m}{e_m}$（表达式符合 $e_m$ 越小，$\alpha_m$ 越大，源自前向分步算法的 $\alpha$）</p>
</li>
<li><p>更新训练数据集的权值分布</p>
<p>$D_{m+1}=(w_{m+1,1},…,w_{m+1,i},…,w_{m+1,N})$</p>
<p>$w_{m+1,i}=\frac{w_{mi}}{Z_m}exp(-\alpha_my_iG_m(x_i)),\ i=1,2,…,N$</p>
<p>此处 $Z_m$ 为规范化因子，$Z_m=\sum_{i=1}^Nw_{mi}exp(-\alpha_my_iG_m(x_i))$</p>
</li>
</ul>
</li>
<li><p>构建基本分类器的线性结合 $f(x)=\sum_{m=1}^M\alpha_mG_m(x)$（$\alpha_m$ 为权重（可信程度））</p>
</li>
</ol>
<p>得到最终分类器 $G(x)=sign(f(x))=sign(\sum_{m=1}^M\alpha_mG_m(x))$</p>
</blockquote>
<p>简单来说，<font style="background: #F9EDA6">先初始化每一个训练数据的权值（$w_{1i}=\frac{1}{N}$），然后依次使用不同的分类器进行学习，根据每次学习的误差率计算下一轮各分类器的系数 $\alpha_m$。并通过 $G_m(x)$ 更新每一个训练数据的权值 $w_{m,i}$ 。</font></p>
<h4 id="3-1-前向分步算法和-AdaBoost-算法的关系"><a href="#3-1-前向分步算法和-AdaBoost-算法的关系" class="headerlink" title="3.1 前向分步算法和 AdaBoost 算法的关系"></a>3.1 前向分步算法和 AdaBoost 算法的关系</h4><p>其实，我们可以<font style="background: #FBD4D0">由前向分步算法推导出 AdaBoost 算法</font><strong>（AdaBoost 算法是前向分步算法的一个特例，当基函数为基本分类器时、损失函数为指数函数时，加法模型等价于 AdaBoost 分类器）</strong></p>
<ul>
<li><p>首先我们发现前向分步算法和 AdaBoost 的<font style="background: #F9EDA6">最终分类器</font>都为 $f(x)=\sum_{m=1}^M\alpha_mG_m(x)$</p>
</li>
<li><p>当前向分步算法的损失函数为指数损失函数 $L(y,f(x))=exp[-yf(x)]$ 时，我们求出损失函数</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521162917660.png" alt="image-20210521162917660" style="zoom:30%;" /></li>
<li><p>然后求出使损失达到最小的 <font style="background: #F9EDA6">$\alpha_m^*$ 和 $G_m^*(x)$ </font>就是 AdaBoost 算法中的 $\alpha_m$ 和 $G_m(x)$</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521165013640.png" alt="image-20210521165013640" style="zoom:30%;" />

<p>对于 $\alpha_m$ 的求解，详见第二章（将 $G_m^*(x)$ 带入求解的优化问题，得到 $\alpha_m^*$ 的表达式并对 $\alpha_m^*$ 求导，令导数为 0 求解出 $\alpha_m$） 可得 $\alpha_m^*=\frac{1}{2}ln\frac{1-e_m}{e_m}$ 和 AdaBoost 算法中的 $\alpha_m$ 完全一致</p>
</li>
<li><p>每一轮的<font style="background: #F9EDA6">样本权值 $\overline{w_{m_i}}$ </font>等价</p>
<p>由 $f_m(x)=f_{m-1}(x)+\alpha_mG_m(x)$ 和 $\overline{w_{m,i}}=exp[-y_if_{m-1}(x_i)]$ 可得：</p>
<p>$\overline{w_{m+1,i}}=\overline{w_{m,i}}exp[-y_i\alpha_mG_m(x)]$ 这和 AdaBoost 算法中的样本权值仅相差规范化因子，因而等价。</p>
</li>
</ul>
<br>

<h3 id="4-AdaBoost-算法训练误差分析"><a href="#4-AdaBoost-算法训练误差分析" class="headerlink" title="4. AdaBoost 算法训练误差分析"></a>4. AdaBoost 算法训练误差分析</h3><p>我们希望证明 AdaBoost 算法训练误差具有上界，以证明算法的可靠性</p>
<blockquote>
<p><font style="background: #d4e9d6">定理（AdaBoost 的训练误差界）</font>AdaBoost 算法最终分类器的训练误差界为 $\frac{1}{N}\sum_{i=1}^NI(G(x_i)\neq y_i)\leq \frac{1}{N}\sum_iexp(-y_if(x_i))=\prod_mZ_m$</p>
</blockquote>
<p>这一定理说明，<font style="background: #F9EDA6">可以在每一轮选取适当的 $G_m$ 使得 $Z_m$ 最小，从而使训练误差下降得最快。</font></p>
<p> 先证明左侧的不等号：</p>
<ul>
<li><p>当 $G(x) \neq y_i$ 时，$y_if(x_i)&lt;0$，因而 $exp(-y_if(x_i))\geq1$</p>
<p>因此左侧不等号成立</p>
</li>
</ul>
<p>然后证明右侧等号：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521143133526.png" alt="image-20210521143133526" style="zoom:40%;" />

<h4 id="4-1-二分类问题-AdaBoost-训练误差界"><a href="#4-1-二分类问题-AdaBoost-训练误差界" class="headerlink" title="4.1 二分类问题 AdaBoost 训练误差界"></a>4.1 二分类问题 AdaBoost 训练误差界</h4><blockquote>
<p><font style="background: #d4e9d6">定理（二分类问题 AdaBoost 的训练误差界）</font></p>
<p>$\prod_{m=1}^MZ_m=\prod_{m=1}^M[2\sqrt{e_m(1-e_m)}]=\prod_{m=1}^M\sqrt{(1-4\gamma_m^2)}\leq exp(-2\sum_{i=1}^M\gamma_m^2)$</p>
<p>此处，$\gamma_m=\frac{1}{2}-e_m$</p>
</blockquote>
<p>先证明左侧的两个等号：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521150345484.png" alt="image-20210521150345484" style="zoom:35%;" />

<p>再证明右侧的不等号：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521151531058.png" alt="image-20210521151531058" style="zoom:30%;" />

<br>

<h3 id="5-提升树"><a href="#5-提升树" class="headerlink" title="5. 提升树"></a>5. 提升树</h3><p>提升树是<font style="background: #F9EDA6">以分类树或回归树为基本分类器的提升方法</font>。提升树被认为是统计学习中性能最好的方法之一。</p>
<p>其中，以决策树为基函数的提升方法称为提升树。提升树模型可以表示为<font style="background: #F9EDA6">决策树的加法模型：$f_M(x)=\sum_{m=1}^MT(x;\Theta_m)$</font>，其中 $T(x;\Theta_m)$ 表示决策树，$\Theta_m$ 为决策树的参数，$M$ 为树的个数。</p>
<h4 id="5-1-提升树算法"><a href="#5-1-提升树算法" class="headerlink" title="5.1 提升树算法"></a>5.1 提升树算法</h4> <img src="https://qiniu.xuyuyan.cn/image-20210521095626658.png" alt="image-20210521095626658" style="zoom:35%;" /> 

<h4 id="5-2-梯度提升算法"><a href="#5-2-梯度提升算法" class="headerlink" title="5.2 梯度提升算法"></a>5.2 梯度提升算法</h4><p>提升树利用加法模型和前向分步算法实现学习的优化过程。当损失函数是平方损失函数或指数损失函数时，每一步的优化时很简单的。<font style="background: #F9EDA6">但对一般损失函数而言，我们一般使用梯度提升算法。</font></p>
<p>这是利用最速下降方法的近似方法，其关键是<font style="background: #F9EDA6">将损失函数的负梯度作为残差的近似值</font>。</p>
<img src="https://qiniu.xuyuyan.cn/image-20210521095626658.png" alt="image-20210521095442469" style="zoom:50%;"/>

<br>

<h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h3><p>我们学习了如何<font style="background: #FBD4D0">将多个弱可学习模型组合为一个强可学习模型（提升方法）</font>。</p>
<p>提升方法中一个最具代表性的就是 <font style="background: #FBD4D0">AdaBoost 算法</font>：$f(x)=\sum_{m=1}^M\alpha_mG_m(x)$</p>
<p>通过迭代，每次学习一个基本分类器。在迭代中提高前一轮被错误分类数据的权值；提高分类误差小的基本分类器在结果所占的权值。</p>
<p><font style="background: #FBD4D0">AdaBoost 的训练误差存在上界</font>$\frac{1}{N}\sum_{i=1}^NI(G(x_i)\neq y_i)\leq \frac{1}{N}\sum_iexp(-y_if(x_i))=\prod_mZ_m$</p>
<p>表明可以在每一轮选取适当的 $G_m$ 使得 $Z_m$ 最小，从而使训练误差下降得最快。</p>
<p><font style="background: #FBD4D0">AdaBoost 算法其实是前向分步算法的一个实现</font>。在这个方法里，模型是加法模型，损失函数是指数损失函数，算法是前向分步算法。可以通过第三章的推导得到两者的最终分类模型、每一轮样本权重、分类器和各分类器权重一致/等价。</p>
<p><font style="background: #FBD4D0">提升树是以决策树为基函数的提升方法</font>。因为树的线性组合可以很好的拟合数据，即使数据中的输入与输出之间的关系很复杂，因此提升树是一个高功能的学习方法。包括：</p>
<ul>
<li>使用平方误差损失函数的回归问题（见 5.1）</li>
<li>使用指数损失函数的分类问题</li>
<li>使用一般损失函数的一般决策问题（梯度提升算法，见 5.2）</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>xyy</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://www.xuyuyan.cn/2021/05/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/">http://www.xuyuyan.cn/2021/05/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/</a></span>
                    </p>
                
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"># 机器学习</a>
                    
                        <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"># 统计学习方法</a>
                    
                        <a href="/tags/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/"># 提升方法</a>
                    
                        <a href="/tags/AdaBoost/"># AdaBoost</a>
                    
                        <a href="/tags/%E5%89%8D%E5%90%91%E5%88%86%E6%AD%A5%E6%96%B9%E6%B3%95/"># 前向分步方法</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2021/05/30/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/">《统计机器学习》读书笔记 · EM算法及其推广</a>
            
            
            <a class="next" rel="next" href="/2021/05/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">《统计学习方法》读书笔记 · 支持向量机</a>
            
        </section>


    </article>
</div>


    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="//unpkg.com/gitalk/dist/gitalk.css">
<script src="//unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
      var gitalk = new Gitalk({
        clientID: '4283629b368b1cf98f81',
        clientSecret: '8bb6ce27010c0db8286e943f3765aeae1757de4d',
        repo: 'xyyBlog',
        owner: 'rdzfv',
        admin: 'rdzfv',
        id: md5(location.pathname),      
        labels: 'Gitalk'.split(',').filter(l => l),
        perPage: 10,
        pagerDirection: 'last',
        createIssueManually: true,
        distractionFreeMode: true
      })
      gitalk.render('gitalk-container')
</script>



        </div>
        <footer id="footer" class="footer">
   <div class="copyright">
    <div style="position:fixed;left:8%;bottom:5%;">
        <div id="webpushr-subscription-button" data-button-text="订阅本站" data-subscriber-count-text="人已订阅" data-background-color="#000000"></div>
    </div>
    <div style="display:inline-block;">
        <div> <a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" style="text-decoration: none;color: black;" >浙ICP备19012712号</a> </div>
        <span>© xyy | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
