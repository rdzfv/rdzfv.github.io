<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>《统计学习方法》读书笔记 · 提升方法 | xyy爱吃番茄</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="《统计学习方法》读书笔记提升方法部分">
<meta property="og:type" content="article">
<meta property="og:title" content="《统计学习方法》读书笔记 · 提升方法">
<meta property="og:url" content="http://www.xuyuyan.cn/2021/05/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/index.html">
<meta property="og:site_name" content="xyy爱吃番茄">
<meta property="og:description" content="《统计学习方法》读书笔记提升方法部分">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521101454835.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521102137486.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521104609015.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521162917660.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521165013640.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521143133526.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521150345484.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521151531058.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521095626658.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210521095626658.png">
<meta property="article:published_time" content="2021-05-21T10:12:57.000Z">
<meta property="article:modified_time" content="2021-05-21T10:16:37.000Z">
<meta property="article:author" content="xyy">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="统计学习方法">
<meta property="article:tag" content="提升方法">
<meta property="article:tag" content="AdaBoost">
<meta property="article:tag" content="前向分步方法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qiniu.xuyuyan.cn/image-20210521101454835.png">
  
    <link rel="alternate" href="/atom.xml" title="xyy爱吃番茄" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">xyy爱吃番茄</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://www.xuyuyan.cn"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="《统计学习方法》读书笔记 · 提升方法-提升方法" class="h-entry article article-type-《统计学习方法》读书笔记 · 提升方法" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/05/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" class="article-date">
  <time class="dt-published" datetime="2021-05-21T10:12:57.000Z" itemprop="datePublished">2021-05-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《统计学习方法》读书笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      《统计学习方法》读书笔记 · 提升方法
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>《统计学习方法》读书笔记提升方法部分</p>
<span id="more"></span>

<h3 id="1-提升方法的基本思路"><a href="#1-提升方法的基本思路" class="headerlink" title="1. 提升方法的基本思路"></a>1. 提升方法的基本思路</h3><p>首先介绍两个概念：<code>强可学习</code> 和 <code>弱可学习</code></p>
<p>强可学习就是，存在一个多项式的学习算法可以进行学习，并且正确率很高；弱可学习就是，学习的正确率仅比随机猜测略好。</p>
<p>一般来说，得到一个弱可学习的算法要比得到一个强可学习的算法要简单的多。那么，我们能否通过若弱可学习算法来得到强可学习算法？（这个研究问题就是我们说的提升方法）</p>
<p>对于 <font style="background: #F9EDA6">提升方法</font>来说，我们需要解决两个问题：</p>
<ul>
<li>在每一轮如何改变训练数据的权值或概率分布</li>
<li>如何将弱分类器组合成一个强分类器</li>
</ul>
<p>对于问题一，AdaBoost 的做法是， <font style="background: #F9EDA6">提高那些被前一轮分类器错误分类样本的权值</font>。也就是希望之后的分类器更加关注之前出错的样本。</p>
<p>对于问题二，AdaBoost 采取 <font style="background: #F9EDA6">加权多数表决</font>的方法，加大分类误差率小的弱分类器的权值。</p>
<br>

<h3 id="2-前向分步算法"><a href="#2-前向分步算法" class="headerlink" title="2. 前向分步算法"></a>2. 前向分步算法</h3><p>假设<font style="background: #d4e9d6">模型为 $f(x)=\sum_{m=1}^M\alpha_mG_m(x)$。$G_m(x)$ 为基函数</font>。</p>
<p>前向分步算法的思路是：因为学习的是加法模型，如果可以<font style="background: #F9EDA6">从前往后，每一步只学习一个基函数及其系数，逐步逼近目标函数</font>。就可以简化优化的复杂度。</p>
<img src="https://qiniu.xuyuyan.cn/image-20210521101454835.png" alt="image-20210521101454835" style="zoom:45%;" />

<p>将 $f(x)=f_{m-1}(x_i)+\alpha G(x_i)$ 带入损失函数 $loss=exp[-y_if(x)]$ 得到：</p>
<p><font style="background: #d4e9d6">$Loss=arg\ min_{\alpha,G} \sum_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\alpha G(x_i))]$</font></p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521102137486.png" alt="image-20210521102137486" style="zoom:35%;" />

<p>得到 $G$ 的最优解因为 $G_m^*=arg\ min_a \sum_i \overline{w_{m_i}}[y_i\neq G(x_i)]$</p>
<p>接下来求 $\alpha$ 的最优解：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521104609015.png" alt="image-20210521104609015" style="zoom:40%;" />

<p>至此我们得到了参数 $G$ 和 $\alpha$ </p>
<p>更新 $f_m(x)=f_{m-1}(x)+\alpha G(x)$</p>
<p>得到加法模型 $f(x)=f_M(x)=\sum_{i=1}^M\alpha_mG(x)$</p>
<blockquote>
<p><font style="background: #d4e9d6">算法（前向分步算法）</font>：</p>
<p>输入：训练数据集 $T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中 $x_i \in R^n,y_i \in {-1,+1}$；</p>
<p>输出：加法模型 $f(x)$</p>
<ol>
<li><p>初始化 $f_0(x)=0$</p>
</li>
<li><p>对 $m=1,2,…,M$</p>
<ul>
<li><p>极小化损失函数：$Loss=arg\ min_{\alpha,G} \sum_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\alpha G(x_i))]$</p>
<p>解得参数 $G$ 和 $\alpha$</p>
</li>
<li><p>更新 $f_m(x)=f_{m-1}(x)+\alpha G(x)$</p>
</li>
</ul>
</li>
<li><p>得到加法模型 $f(x)=f_M(x)=\sum_{i=1}^M\alpha_mG(x)$</p>
</li>
</ol>
<p>这样，前向分步算法<font style="background: #FBD4D0">将 “同时求解从 m = 1 到 M 所有参数的优化问题” 简化为 “逐次求解各个参数的优化问题” </font></p>
</blockquote>
<br>

<h3 id="3-AdaBoost-算法"><a href="#3-AdaBoost-算法" class="headerlink" title="3. AdaBoost 算法"></a>3. AdaBoost 算法</h3><p>AdaBoost 算法是一个非常具有代表性的提升方法。从训练数据中学习一系列弱分类器或基本分类器，并将这些弱分类器线性组合成一个强分类器。</p>
<blockquote>
<p><font style="background: #d4e9d6">算法（AdaBoost）</font>：</p>
<p>输入：训练数据集 $T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中 $x_i \in R^n,y_i \in {-1,+1}$；弱学习算法</p>
<p>输出：最终分类器 $G(x)$</p>
<ol>
<li><p>初始化训练数据的权值分布</p>
<p>$D_1=(w_{11},…,w_{1i},…,w_{1N}),w_{1i}=\frac{1}{N},i=1,2,…,N$</p>
</li>
<li><p>对 $m=1,2,…,M$ （不同分类器）</p>
<ul>
<li><p>使用权值分布 $D_m$ 的训练数据集学习，得到基本分类器 $G_m(x):\chi \rightarrow {-1,+1}$</p>
</li>
<li><p>计算 $G_m(x)$ 在训练数据集上的分类误差率 $e_m=\sum_{i=1}^NP(G_m(x_i)\neq y_i)=\sum_{i=1}^Nw_{mi}I(G_m(x_i)\neq y_i)$</p>
<p>（将分类错误的样本对应的权值求和）</p>
</li>
<li><p>计算 $G_m(x)$ 的系数 $\alpha_m=\frac{1}{2}ln\frac{1-e_m}{e_m}$（表达式符合 $e_m$ 越小，$\alpha_m$ 越大，源自前向分步算法的 $\alpha$）</p>
</li>
<li><p>更新训练数据集的权值分布</p>
<p>$D_{m+1}=(w_{m+1,1},…,w_{m+1,i},…,w_{m+1,N})$</p>
<p>$w_{m+1,i}=\frac{w_{mi}}{Z_m}exp(-\alpha_my_iG_m(x_i)),\ i=1,2,…,N$</p>
<p>此处 $Z_m$ 为规范化因子，$Z_m=\sum_{i=1}^Nw_{mi}exp(-\alpha_my_iG_m(x_i))$</p>
</li>
</ul>
</li>
<li><p>构建基本分类器的线性结合 $f(x)=\sum_{m=1}^M\alpha_mG_m(x)$（$\alpha_m$ 为权重（可信程度））</p>
</li>
</ol>
<p>得到最终分类器 $G(x)=sign(f(x))=sign(\sum_{m=1}^M\alpha_mG_m(x))$</p>
</blockquote>
<p>简单来说，<font style="background: #F9EDA6">先初始化每一个训练数据的权值（$w_{1i}=\frac{1}{N}$），然后依次使用不同的分类器进行学习，根据每次学习的误差率计算下一轮各分类器的系数 $\alpha_m$。并通过 $G_m(x)$ 更新每一个训练数据的权值 $w_{m,i}$ 。</font></p>
<h4 id="3-1-前向分步算法和-AdaBoost-算法的关系"><a href="#3-1-前向分步算法和-AdaBoost-算法的关系" class="headerlink" title="3.1 前向分步算法和 AdaBoost 算法的关系"></a>3.1 前向分步算法和 AdaBoost 算法的关系</h4><p>其实，我们可以<font style="background: #FBD4D0">由前向分步算法推导出 AdaBoost 算法</font><strong>（AdaBoost 算法是前向分步算法的一个特例，当基函数为基本分类器时、损失函数为指数函数时，加法模型等价于 AdaBoost 分类器）</strong></p>
<ul>
<li><p>首先我们发现前向分步算法和 AdaBoost 的<font style="background: #F9EDA6">最终分类器</font>都为 $f(x)=\sum_{m=1}^M\alpha_mG_m(x)$</p>
</li>
<li><p>当前向分步算法的损失函数为指数损失函数 $L(y,f(x))=exp[-yf(x)]$ 时，我们求出损失函数</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521162917660.png" alt="image-20210521162917660" style="zoom:30%;" /></li>
<li><p>然后求出使损失达到最小的 <font style="background: #F9EDA6">$\alpha_m^*$ 和 $G_m^*(x)$ </font>就是 AdaBoost 算法中的 $\alpha_m$ 和 $G_m(x)$</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521165013640.png" alt="image-20210521165013640" style="zoom:30%;" />

<p>对于 $\alpha_m$ 的求解，详见第二章（将 $G_m^*(x)$ 带入求解的优化问题，得到 $\alpha_m^*$ 的表达式并对 $\alpha_m^*$ 求导，令导数为 0 求解出 $\alpha_m$） 可得 $\alpha_m^*=\frac{1}{2}ln\frac{1-e_m}{e_m}$ 和 AdaBoost 算法中的 $\alpha_m$ 完全一致</p>
</li>
<li><p>每一轮的<font style="background: #F9EDA6">样本权值 $\overline{w_{m_i}}$ </font>等价</p>
<p>由 $f_m(x)=f_{m-1}(x)+\alpha_mG_m(x)$ 和 $\overline{w_{m,i}}=exp[-y_if_{m-1}(x_i)]$ 可得：</p>
<p>$\overline{w_{m+1,i}}=\overline{w_{m,i}}exp[-y_i\alpha_mG_m(x)]$ 这和 AdaBoost 算法中的样本权值仅相差规范化因子，因而等价。</p>
</li>
</ul>
<br>

<h3 id="4-AdaBoost-算法训练误差分析"><a href="#4-AdaBoost-算法训练误差分析" class="headerlink" title="4. AdaBoost 算法训练误差分析"></a>4. AdaBoost 算法训练误差分析</h3><p>我们希望证明 AdaBoost 算法训练误差具有上界，以证明算法的可靠性</p>
<blockquote>
<p><font style="background: #d4e9d6">定理（AdaBoost 的训练误差界）</font>AdaBoost 算法最终分类器的训练误差界为 $\frac{1}{N}\sum_{i=1}^NI(G(x_i)\neq y_i)\leq \frac{1}{N}\sum_iexp(-y_if(x_i))=\prod_mZ_m$</p>
</blockquote>
<p>这一定理说明，<font style="background: #F9EDA6">可以在每一轮选取适当的 $G_m$ 使得 $Z_m$ 最小，从而使训练误差下降得最快。</font></p>
<p> 先证明左侧的不等号：</p>
<ul>
<li><p>当 $G(x) \neq y_i$ 时，$y_if(x_i)&lt;0$，因而 $exp(-y_if(x_i))\geq1$</p>
<p>因此左侧不等号成立</p>
</li>
</ul>
<p>然后证明右侧等号：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521143133526.png" alt="image-20210521143133526" style="zoom:40%;" />

<h4 id="4-1-二分类问题-AdaBoost-训练误差界"><a href="#4-1-二分类问题-AdaBoost-训练误差界" class="headerlink" title="4.1 二分类问题 AdaBoost 训练误差界"></a>4.1 二分类问题 AdaBoost 训练误差界</h4><blockquote>
<p><font style="background: #d4e9d6">定理（二分类问题 AdaBoost 的训练误差界）</font></p>
<p>$\prod_{m=1}^MZ_m=\prod_{m=1}^M[2\sqrt{e_m(1-e_m)}]=\prod_{m=1}^M\sqrt{(1-4\gamma_m^2)}\leq exp(-2\sum_{i=1}^M\gamma_m^2)$</p>
<p>此处，$\gamma_m=\frac{1}{2}-e_m$</p>
</blockquote>
<p>先证明左侧的两个等号：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521150345484.png" alt="image-20210521150345484" style="zoom:35%;" />

<p>再证明右侧的不等号：</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210521151531058.png" alt="image-20210521151531058" style="zoom:30%;" />

<br>

<h3 id="5-提升树"><a href="#5-提升树" class="headerlink" title="5. 提升树"></a>5. 提升树</h3><p>提升树是<font style="background: #F9EDA6">以分类树或回归树为基本分类器的提升方法</font>。提升树被认为是统计学习中性能最好的方法之一。</p>
<p>其中，以决策树为基函数的提升方法称为提升树。提升树模型可以表示为<font style="background: #F9EDA6">决策树的加法模型：$f_M(x)=\sum_{m=1}^MT(x;\Theta_m)$</font>，其中 $T(x;\Theta_m)$ 表示决策树，$\Theta_m$ 为决策树的参数，$M$ 为树的个数。</p>
<h4 id="5-1-提升树算法"><a href="#5-1-提升树算法" class="headerlink" title="5.1 提升树算法"></a>5.1 提升树算法</h4> <img src="https://qiniu.xuyuyan.cn/image-20210521095626658.png" alt="image-20210521095626658" style="zoom:35%;" /> 

<h4 id="5-2-梯度提升算法"><a href="#5-2-梯度提升算法" class="headerlink" title="5.2 梯度提升算法"></a>5.2 梯度提升算法</h4><p>提升树利用加法模型和前向分步算法实现学习的优化过程。当损失函数是平方损失函数或指数损失函数时，每一步的优化时很简单的。<font style="background: #F9EDA6">但对一般损失函数而言，我们一般使用梯度提升算法。</font></p>
<p>这是利用最速下降方法的近似方法，其关键是<font style="background: #F9EDA6">将损失函数的负梯度作为残差的近似值</font>。</p>
<img src="https://qiniu.xuyuyan.cn/image-20210521095626658.png" alt="image-20210521095442469" style="zoom:50%;"/>

<br>

<h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h3><p>我们学习了如何<font style="background: #FBD4D0">将多个弱可学习模型组合为一个强可学习模型（提升方法）</font>。</p>
<p>提升方法中一个最具代表性的就是 <font style="background: #FBD4D0">AdaBoost 算法</font>：$f(x)=\sum_{m=1}^M\alpha_mG_m(x)$</p>
<p>通过迭代，每次学习一个基本分类器。在迭代中提高前一轮被错误分类数据的权值；提高分类误差小的基本分类器在结果所占的权值。</p>
<p><font style="background: #FBD4D0">AdaBoost 的训练误差存在上界</font>$\frac{1}{N}\sum_{i=1}^NI(G(x_i)\neq y_i)\leq \frac{1}{N}\sum_iexp(-y_if(x_i))=\prod_mZ_m$</p>
<p>表明可以在每一轮选取适当的 $G_m$ 使得 $Z_m$ 最小，从而使训练误差下降得最快。</p>
<p><font style="background: #FBD4D0">AdaBoost 算法其实是前向分步算法的一个实现</font>。在这个方法里，模型是加法模型，损失函数是指数损失函数，算法是前向分步算法。可以通过第三章的推导得到两者的最终分类模型、每一轮样本权重、分类器和各分类器权重一致/等价。</p>
<p><font style="background: #FBD4D0">提升树是以决策树为基函数的提升方法</font>。因为树的线性组合可以很好的拟合数据，即使数据中的输入与输出之间的关系很复杂，因此提升树是一个高功能的学习方法。包括：</p>
<ul>
<li>使用平方误差损失函数的回归问题（见 5.1）</li>
<li>使用指数损失函数的分类问题</li>
<li>使用一般损失函数的一般决策问题（梯度提升算法，见 5.2）</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.xuyuyan.cn/2021/05/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" data-id="ckwknngp2000tfcufa3im2tym" data-title="《统计学习方法》读书笔记 · 提升方法" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AdaBoost/" rel="tag">AdaBoost</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%89%8D%E5%90%91%E5%88%86%E6%AD%A5%E6%96%B9%E6%B3%95/" rel="tag">前向分步方法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" rel="tag">提升方法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/05/30/EM%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E6%8E%A8%E5%B9%BF/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          《统计机器学习》读书笔记 · EM算法及其推广
        
      </div>
    </a>
  
  
    <a href="/2021/05/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">《统计学习方法》读书笔记 · 支持向量机</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《统计学习方法》读书笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E7%A2%8E%E7%A2%8E%E5%BF%B5/">个人碎碎念</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/">离散数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/">软件测试</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%A2%E7%BB%8F/">面经</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AdaBoost/" rel="tag">AdaBoost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM-%E7%AE%97%E6%B3%95/" rel="tag">EM 算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UI%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/" rel="tag">UI自动化测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k-%E8%BF%91%E9%82%BB/" rel="tag">k 近邻</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kd-%E6%A0%91/" rel="tag">kd 树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/" rel="tag">代理模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" rel="tag">决策树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95/" rel="tag">分治算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E5%90%91%E5%88%86%E6%AD%A5%E6%96%B9%E6%B3%95/" rel="tag">前向分步方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="tag">动态规划</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/" rel="tag">原型模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E6%BA%AF/" rel="tag">回溯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%A0%E7%89%B9%E7%BD%91%E5%8E%86%E5%8F%B2/" rel="tag">因特网历史</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE/" rel="tag">图</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/" rel="tag">图算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" rel="tag">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" rel="tag">工厂方法模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" rel="tag">并查集</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/" rel="tag">微信小程序</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" rel="tag">感知机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" rel="tag">提升方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" rel="tag">支持向量机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E8%AE%BA/" rel="tag">数论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" rel="tag">最大熵模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/" rel="tag">朴素贝叶斯算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" rel="tag">极大似然估计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" rel="tag">模板方法模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AF%95%E4%B8%9A/" rel="tag">毕业</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AF%95%E4%B8%9A%E6%97%85%E8%A1%8C/" rel="tag">毕业旅行</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" rel="tag">离散数学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/" rel="tag">策略模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/" rel="tag">装饰模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" rel="tag">设计原则</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/" rel="tag">贝叶斯估计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" rel="tag">软件测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%92%E5%BD%92/" rel="tag">递归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92/" rel="tag">逻辑斯谛回归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%95%BF%E6%B2%99/" rel="tag">长沙</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E7%BB%8F/" rel="tag">面经</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/" rel="tag">高斯分布</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AdaBoost/" style="font-size: 10px;">AdaBoost</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/EM-%E7%AE%97%E6%B3%95/" style="font-size: 10px;">EM 算法</a> <a href="/tags/UI%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">UI自动化测试</a> <a href="/tags/k-%E8%BF%91%E9%82%BB/" style="font-size: 10px;">k 近邻</a> <a href="/tags/kd-%E6%A0%91/" style="font-size: 10px;">kd 树</a> <a href="/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">代理模式</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 10px;">决策树</a> <a href="/tags/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95/" style="font-size: 10px;">分治算法</a> <a href="/tags/%E5%89%8D%E5%90%91%E5%88%86%E6%AD%A5%E6%96%B9%E6%B3%95/" style="font-size: 10px;">前向分步方法</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">动态规划</a> <a href="/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">原型模式</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 10px;">回溯</a> <a href="/tags/%E5%9B%A0%E7%89%B9%E7%BD%91%E5%8E%86%E5%8F%B2/" style="font-size: 10px;">因特网历史</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/" style="font-size: 10px;">图算法</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">工厂方法模式</a> <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" style="font-size: 10px;">并查集</a> <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/" style="font-size: 10px;">微信小程序</a> <a href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" style="font-size: 10px;">感知机</a> <a href="/tags/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" style="font-size: 10px;">提升方法</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">操作系统</a> <a href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 10px;">支持向量机</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 10px;">数据结构</a> <a href="/tags/%E6%95%B0%E8%AE%BA/" style="font-size: 10px;">数论</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">最大熵模型</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/" style="font-size: 10px;">朴素贝叶斯算法</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">机器学习</a> <a href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" style="font-size: 10px;">极大似然估计</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">模板方法模式</a> <a href="/tags/%E6%AF%95%E4%B8%9A/" style="font-size: 10px;">毕业</a> <a href="/tags/%E6%AF%95%E4%B8%9A%E6%97%85%E8%A1%8C/" style="font-size: 10px;">毕业旅行</a> <a href="/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" style="font-size: 15px;">离散数学</a> <a href="/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">策略模式</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 20px;">统计学习方法</a> <a href="/tags/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">装饰模式</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">计算机网络</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" style="font-size: 10px;">设计原则</a> <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/" style="font-size: 10px;">贝叶斯估计</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">软件测试</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">逻辑斯谛回归</a> <a href="/tags/%E9%95%BF%E6%B2%99/" style="font-size: 10px;">长沙</a> <a href="/tags/%E9%9D%A2%E7%BB%8F/" style="font-size: 10px;">面经</a> <a href="/tags/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/" style="font-size: 10px;">高斯分布</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/11/29/public/webpushr-sw/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/29/public/newPost/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/30/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/">《统计学习方法》读书笔记 · 隐马尔可夫模型</a>
          </li>
        
          <li>
            <a href="/2021/06/24/2021%E6%AF%95%E4%B8%9A%E7%A2%8E%E7%A2%8E%E5%BF%B5/">2021毕业碎碎念</a>
          </li>
        
          <li>
            <a href="/2021/06/24/%E6%AF%95%E4%B8%9A%E6%97%85%E8%A1%8C2021/">毕业旅行2021</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 xyy<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>