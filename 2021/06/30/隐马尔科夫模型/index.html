<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>《统计学习方法》读书笔记 · 隐马尔可夫模型 | xyy爱吃番茄</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="《统计学习方法》隐马尔可夫模型部分读书笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="《统计学习方法》读书笔记 · 隐马尔可夫模型">
<meta property="og:url" content="http://www.xuyuyan.cn/2021/06/30/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="xyy爱吃番茄">
<meta property="og:description" content="《统计学习方法》隐马尔可夫模型部分读书笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://n.sinaimg.cn/sinacn20200201ac/221/w1330h491/20200201/0bb4-intiarp9451425.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210608120327255.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210608154301221.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210608170544099.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210628111835743.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210628114128973.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210628114749674.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210630093439226.png">
<meta property="og:image" content="https://qiniu.xuyuyan.cn/image-20210630095130731.png">
<meta property="article:published_time" content="2021-06-30T06:26:08.000Z">
<meta property="article:modified_time" content="2021-06-30T06:43:56.000Z">
<meta property="article:author" content="xyy">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="统计学习方法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://n.sinaimg.cn/sinacn20200201ac/221/w1330h491/20200201/0bb4-intiarp9451425.png">
  
    <link rel="alternate" href="/atom.xml" title="xyy爱吃番茄" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">xyy爱吃番茄</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://www.xuyuyan.cn"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-隐马尔科夫模型" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/30/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/" class="article-date">
  <time class="dt-published" datetime="2021-06-30T06:26:08.000Z" itemprop="datePublished">2021-06-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《统计学习方法》读书笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      《统计学习方法》读书笔记 · 隐马尔可夫模型
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>《统计学习方法》隐马尔可夫模型部分读书笔记</p>
<span id="more"></span>

<h3 id="0-引入"><a href="#0-引入" class="headerlink" title="0. 引入"></a>0. 引入</h3><p>我们举一个例子，如果我们想要预测股市的走向。如果使用朴素贝叶斯算法，则需要有一个强假设“各特征为独立分布”，但显然，每一日的股票走向是相互影响的。因此，如果用一句通俗易懂的文字描述隐马尔可夫模型，就是该模型会（仅）参考前一次的分布对下一步的分布进行预测。</p>
<p><img src="https://n.sinaimg.cn/sinacn20200201ac/221/w1330h491/20200201/0bb4-intiarp9451425.png" alt="查看源图像"></p>
<br>

<h3 id="2-隐马尔可夫模型"><a href="#2-隐马尔可夫模型" class="headerlink" title="2. 隐马尔可夫模型"></a>2. 隐马尔可夫模型</h3><h4 id="2-1-名词介绍"><a href="#2-1-名词介绍" class="headerlink" title="2.1 名词介绍"></a>2.1 名词介绍</h4><p>我们将事物的变化抽象为状态的变化，对应观测值的变化。同一事物所有可能的<strong>状态的集合</strong>记作 Q；所有可能的<strong>观测值的集合</strong>记作 V。结合时间维度，我们将事物随时间变化的<strong>状态序列集合</strong>记为 I；将事物随时间变化的<strong>观测序列集合</strong>记为 O。                                                                  </p>
<p>同时定义了<strong>状态转移矩阵</strong> A(N*N)，反映了从迁移状态 $i_1$ 转变到下一状态 $i_2$ 的概率。N 为状态类别的数量。其中 $a_{1j}$ 表示 $a_{1j}=P(i_2=q_j|i_1=q_1)$，即上一状态为 $q_1$ 且当前状态为 $q_j$ 时的概率，即表格的第一行为当前状态，第一列为上次状态。</p>
<table>
<thead>
<tr>
<th></th>
<th>$i_2=q_1$</th>
<th>$i_2=q_2$</th>
<th>…</th>
<th>$i_2=q_N$</th>
</tr>
</thead>
<tbody><tr>
<td>$i_1=q_1$</td>
<td>$a_{11}$</td>
<td>$a_{12}$</td>
<td>$a_{1j}$</td>
<td></td>
</tr>
<tr>
<td>$i_1=q_2$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>$i_1=q_N$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>也定义了<strong>观测概率矩阵</strong> B(N*M)，反映了从状态 $i_1$ 到观测结果 $o_1$ 的对应关系。N 为状态类别的数量，M 为观测数1。</p>
<table>
<thead>
<tr>
<th></th>
<th>$o_1=v_1$</th>
<th>$o_1=v_2$</th>
<th>…</th>
<th>$o_1=v_m$</th>
</tr>
</thead>
<tbody><tr>
<td>$i_1=q_1$</td>
<td>$a_{11}$</td>
<td>$a_{12}$</td>
<td>$a_{1j}$</td>
<td></td>
</tr>
<tr>
<td>$i_1=q_2$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>$i_1=q_N$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>定义了<strong>初始状态概率向量</strong>（因为在第一个时刻并没有前一状态）：</p>
<p>$\pi = \begin{bmatrix} \pi_1\\ \pi_2\\ … \\ \pi_N \end{bmatrix}=\begin{bmatrix} P(i_1=q_1)\\  P(i_1=q_2) \\ … \\ P(i_1=q_N) \end{bmatrix} $</p>
<h3 id="2-2-隐马尔可夫模型"><a href="#2-2-隐马尔可夫模型" class="headerlink" title="2.2 隐马尔可夫模型"></a>2.2 隐马尔可夫模型</h3><p>我们画出隐马尔可夫模型的示意图：</p>
<p><img src="https://qiniu.xuyuyan.cn/image-20210608120327255.png" alt="image-20210608120327255"></p>
<p>可以发现隐马尔可夫链由状态变量链和观测变量链组成，而状态变量链的递推受约束于状态转移矩阵 A；每一个观测变量受约束于其对应的状态变量，因而受约束于观测概率矩阵 B。因此隐马尔可夫模型可以用 $\lambda=(A,B,\pi)$ 来表示。</p>
<h4 id="2-3-隐马尔可夫的两个基本假设"><a href="#2-3-隐马尔可夫的两个基本假设" class="headerlink" title="2.3 隐马尔可夫的两个基本假设"></a>2.3 隐马尔可夫的两个基本假设</h4><ul>
<li>齐次马尔可夫性假设：假设隐马尔可夫链在任意时刻 t 的状态只能依赖于前一时刻的状态，与其他时刻的状态及观测无关，也与时间 t 无关。</li>
<li>观测独立性假设：假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测和状态无关。</li>
</ul>
<br>

<h3 id="3-隐马尔可夫的三个基本问题"><a href="#3-隐马尔可夫的三个基本问题" class="headerlink" title="3. 隐马尔可夫的三个基本问题"></a>3. 隐马尔可夫的三个基本问题</h3><h4 id="3-1-概率计算问题"><a href="#3-1-概率计算问题" class="headerlink" title="3.1 概率计算问题"></a>3.1 概率计算问题</h4><p>概率计算问题解决的是给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,…,o_T)$，计算在模型 $\lambda$ 下观测序列 O 出现的概率 $P(O|\lambda)$。</p>
<h5 id="3-1-1-直接计算法"><a href="#3-1-1-直接计算法" class="headerlink" title="3.1.1 直接计算法"></a>3.1.1 直接计算法</h5><p>通过列举所有可能的状态序列列表 I，求各个状态序列 I 与观测序列 O 的联合概率 。</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210608154301221.png" alt="image-20210608154301221" style="zoom:35%;" />

<p>但是这个方法的计算量很大，时间复杂度为 $O(TN^T)$。</p>
<h5 id="3-1-2-前向算法"><a href="#3-1-2-前向算法" class="headerlink" title="3.1.2 前向算法"></a>3.1.2 前向算法</h5><p>我们定义前向概率：给定隐马尔可夫模型 $\lambda$，定义时刻 t 观测序列为 $o_1,o_2,…,o_t$ 且状态为 $q_i$ 的概率为前向概率，记作 $\alpha_t(i)=P(o_1,o_2,…,o_t,i_t=q_i|\lambda)$</p>
<blockquote>
<p>算法（观测序列概率的前向算法）：</p>
<p>输入：隐马尔可夫模型 $\lambda$，观测序列 O；</p>
<p>输出：观测序列概率 $P(O|\lambda)$</p>
<ol>
<li><p>初值：$\alpha_1(i)=\pi_ib_i(o_1)$</p>
</li>
<li><p>递推：对 $t=1,2,…,T-1$</p>
<p>$\alpha_{t+1}(i)=[\sum_{j=1}^N\alpha_t(j)a_{ji}]b_i(o_{t+1})$</p>
</li>
<li><p>终值：$P(O|\lambda)=\sum_{i=1}^N\alpha_T(i)$</p>
</li>
</ol>
</blockquote>
 <img src="https://qiniu.xuyuyan.cn/image-20210608170544099.png" alt="image-20210608170544099" style="zoom:35%;" />

<p>时间复杂度为 $O(N^2T)$</p>
<h5 id="3-1-3-后向算法"><a href="#3-1-3-后向算法" class="headerlink" title="3.1.3 后向算法"></a>3.1.3 后向算法</h5><p>我们定义后向概率：给定隐马尔可夫模型 $\lambda$，定义在时刻 t 状态为 $q_i$ 的条件下，从 t+1 到 T 的部分观测序列为 $o_{t+1},o_{t+2},…,o_T$ 的概率，记作 $\beta_t(i)=P(o_{t+1},o_{t+2},..,o_T|i_t=q,\lambda)$</p>
<blockquote>
<p>算法（观测序列概率的后向算法）：</p>
<p>输入：隐马尔可夫模型 $\lambda$，观测序列 O；</p>
<p>输出：观测序列概率 $P(O|\lambda)$</p>
<ol>
<li><p>初值：$\beta_T(i)=1$</p>
</li>
<li><p>对 $t=T-1,T-2,…,1$</p>
<p>$\beta_t(i)=\sum_{j=1}^Na_{ij}b_j(o_{t+1})\beta_{t+1}(j)$</p>
</li>
<li><p>终值：$P(O|\lambda)=\sum_{i=1}^N\pi_ib_i(o_1)\beta_1(i)$</p>
</li>
</ol>
</blockquote>
   <img src="https://qiniu.xuyuyan.cn/image-20210628111835743.png" alt="image-20210628111835743" style="zoom:40%;" />

<h4 id="3-2-学习问题"><a href="#3-2-学习问题" class="headerlink" title="3.2 学习问题"></a>3.2 学习问题</h4><p>学习问题是已知观测序列 $O=(o_1,o_2,…,o_T)$，估计模型 $\lambda=(A,B,\pi)$ 参数，使得在模型下观测序列概率 $P(O|\lambda)$ 最大，即用极大似然估计的方法估计参数。</p>
<h5 id="3-2-1-监督学习方法"><a href="#3-2-1-监督学习方法" class="headerlink" title="3.2.1 监督学习方法"></a>3.2.1 监督学习方法</h5><p>此处的训练数据为观测序列和对应的状态序列，即 ${(O_1,I_1),(O_2,I_2),…,(O_S,I_S)}$ 。可以使用极大似然估计方法来估计隐马尔可夫模型的参数。</p>
<ol>
<li><p>转移概率 $a_{ij}$ 的估计</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210628114128973.png" alt="image-20210628114128973" style="zoom:40%;" /></li>
<li><p>观测概率 $b_j(k)$ 的估计</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210628114749674.png" alt="image-20210628114749674" style="zoom:40%;" /></li>
<li><p>初始状态概率 $\pi_i$ 的估计 $\hat \pi_i$ 为 S 个样本中初始状态为 $q_i$ 的频率</p>
</li>
</ol>
<h5 id="3-2-2-无监督学习方法（Baum-Welch）"><a href="#3-2-2-无监督学习方法（Baum-Welch）" class="headerlink" title="3.2.2 无监督学习方法（Baum-Welch）"></a>3.2.2 无监督学习方法（Baum-Welch）</h5><p>由于监督学习需要使用标注的训练数据，而人工标注训练数据往往代价很高，有时会利用无监督学习的方法。</p>
<p>不难发现，隐马尔可夫模型是一个含有隐变量的概率模型 $P(O|\lambda)=\sum_{I}P(O|I,\lambda)P(I|\lambda)$，他的参数学习可以使用 EM 算法实现。（我们的目标是学习隐马尔可夫模型 $\lambda=(A,B,\pi)$ 的参数，状态序列数据 I 为不可观测的隐数据）</p>
<ol>
<li><p>确定完全数据的对数似然函数 $log P(O,I|\lambda)$</p>
</li>
<li><p>EM 算法的 E 步：求 Q 函数 $Q(\lambda, \overline{\lambda})$</p>
<img src="https://qiniu.xuyuyan.cn/image-20210630093439226.png" alt="image-20210630093439226" style="zoom:33%;" /></li>
<li><p>EM 算法的 M 步：极大化 Q 函数，求模型参数 $A,B,\pi$</p>
<p>依次求偏导并令其结果为 0，求解参数。</p>
</li>
</ol>
<h4 id="3-3-预测问题"><a href="#3-3-预测问题" class="headerlink" title="3.3 预测问题"></a>3.3 预测问题</h4><p>预测问题也称解码问题，已知模型 $\lambda=(A,B,\pi)$ 参数和观测序列 $O=(o_1,o_2,…,o_T)$，求对给定观测序列条件概率 $P(I|O)$ 最大的状态序列 $I=(i_1,i_2,…,i_T)$。即给定观测序列，求最有可能的对应的状态序列。</p>
<ul>
<li><p>维比特算法</p>
<p>维比特算法即用动态规划求概率最大路径（最优路径）。（一条路径对应一个状态序列）</p>
 <img src="https://qiniu.xuyuyan.cn/image-20210630095130731.png" alt="image-20210630095130731" style="zoom:45%;" />

<p>首先导入两个变量 $\delta$ 和 $\phi$。</p>
<ul>
<li><p>定义在时刻 t 状态为 i 的所有单个路径 $(i_1,i_2,…,i_t)$ 中概率最大值为 $\delta_t(i)=max_{i_1,i_2,…,i_{t-1}}P(i_t=i,i_{t-1},…,i_1,o_t,…,o_1|\lambda)$。</p>
<p>由此可以得到变量 $\delta$ 的递推公式：</p>
<p>$\delta_{t+1}(i)=max_{i_1,i_2,…,i_t}P(i_{t+1}=i,i_t,…,i_1,o_{t+1},…,o_1|\lambda)$</p>
<p>$=max_{1\leq j\leq N}[\delta_t(j)a_{ji}]b_i(o_{t+1})$</p>
</li>
<li><p>定义在时刻 t 状态为 i 的所有单个路径 $(i_1,i_2,…,i_{t-1},i)$ 中概率最大的路径的第 t-1 个节点为 $\phi_t(i)=arg \ max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]$</p>
</li>
</ul>
<p>输入：模型 $\lambda=(A,B,\pi)$ 和观测 $O=(o_1,o_2,…,o_T)$</p>
<p>输出：最优路径 $I=(i_1,i_2,…,i_T)$</p>
<ol>
<li><p>初始化：</p>
<p>$\delta_1(i)=\pi_ib_i(o_1)$，$i=1,2,…,N$</p>
<p>$\phi_1(i)=0$，$i=1,2,…,N$</p>
</li>
<li><p>递推。对 $t=2,3,…,T_j$</p>
<p>在时刻 t 所有状态为 i 的所有路径中概率最大值：$\delta_1(i)=max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]b_i(o_t)$，$i=1,2,…,N$</p>
<p>用于存最优路径：$\phi_t(i)=arg \ max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]$，$i=1,2,…,N$</p>
</li>
<li><p>终止</p>
<p>$P^*=max_{1\leq j\leq N}\ \delta_{T}(i)$</p>
</li>
<li><p>最优路径回溯。</p>
<p>对 $t=T-1,T-2,…,1$，$i_t=\phi_{t+1}(i_{t+1})$</p>
</li>
</ol>
</li>
</ul>
<br>

<h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h3><p>隐马尔可夫可以理解为朴素贝叶斯的一个改进，去除了强假设“各特征为独立分布”，（仅）参考前一次的分布对下一步的分布进行预测。</p>
<ul>
<li><p>我们可以通过直接概率计算（时间复杂度大），或是前向、后向方法计算在模型 $\lambda$ 下观测序列 O 出现的概率 $P(O|\lambda)$。</p>
</li>
<li><p>然后通过上一步得到的观测序列 O，用于学习模型参数的训练数据。可分为监督学习（使用极大似然估计）和无监督学习（使用 EM 算法）。</p>
</li>
<li><p>最后是使用训练好的模型进行预测。一般使用维比特算法（用动态规划求概率最大路径）。最终得到概率最大的路径（即每一个时间节点下的估计值）</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://www.xuyuyan.cn/2021/06/30/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/" data-id="ckwknngra003vfcuf2k998gfm" data-title="《统计学习方法》读书笔记 · 隐马尔可夫模型" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/11/29/public/newPost/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2021/06/24/2021%E6%AF%95%E4%B8%9A%E7%A2%8E%E7%A2%8E%E5%BF%B5/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">2021毕业碎碎念</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《统计学习方法》读书笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%B8%AA%E4%BA%BA%E7%A2%8E%E7%A2%8E%E5%BF%B5/">个人碎碎念</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/">离散数学</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/">软件测试</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%A2%E7%BB%8F/">面经</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AdaBoost/" rel="tag">AdaBoost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DFS/" rel="tag">DFS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM-%E7%AE%97%E6%B3%95/" rel="tag">EM 算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UI%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/" rel="tag">UI自动化测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k-%E8%BF%91%E9%82%BB/" rel="tag">k 近邻</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kd-%E6%A0%91/" rel="tag">kd 树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/" rel="tag">代理模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" rel="tag">决策树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95/" rel="tag">分治算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E5%90%91%E5%88%86%E6%AD%A5%E6%96%B9%E6%B3%95/" rel="tag">前向分步方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="tag">动态规划</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/" rel="tag">原型模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%9E%E6%BA%AF/" rel="tag">回溯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%A0%E7%89%B9%E7%BD%91%E5%8E%86%E5%8F%B2/" rel="tag">因特网历史</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE/" rel="tag">图</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/" rel="tag">图算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" rel="tag">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" rel="tag">工厂方法模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" rel="tag">并查集</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/" rel="tag">微信小程序</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" rel="tag">感知机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" rel="tag">提升方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="tag">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" rel="tag">支持向量机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" rel="tag">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E8%AE%BA/" rel="tag">数论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" rel="tag">最大熵模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/" rel="tag">朴素贝叶斯算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" rel="tag">极大似然估计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" rel="tag">模板方法模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AF%95%E4%B8%9A/" rel="tag">毕业</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%AF%95%E4%B8%9A%E6%97%85%E8%A1%8C/" rel="tag">毕业旅行</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" rel="tag">离散数学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/" rel="tag">策略模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/" rel="tag">装饰模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" rel="tag">设计原则</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/" rel="tag">贝叶斯估计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" rel="tag">软件测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%92%E5%BD%92/" rel="tag">递归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92/" rel="tag">逻辑斯谛回归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%95%BF%E6%B2%99/" rel="tag">长沙</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E7%BB%8F/" rel="tag">面经</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/" rel="tag">高斯分布</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AdaBoost/" style="font-size: 10px;">AdaBoost</a> <a href="/tags/DFS/" style="font-size: 10px;">DFS</a> <a href="/tags/EM-%E7%AE%97%E6%B3%95/" style="font-size: 10px;">EM 算法</a> <a href="/tags/UI%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">UI自动化测试</a> <a href="/tags/k-%E8%BF%91%E9%82%BB/" style="font-size: 10px;">k 近邻</a> <a href="/tags/kd-%E6%A0%91/" style="font-size: 10px;">kd 树</a> <a href="/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">代理模式</a> <a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 10px;">决策树</a> <a href="/tags/%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95/" style="font-size: 10px;">分治算法</a> <a href="/tags/%E5%89%8D%E5%90%91%E5%88%86%E6%AD%A5%E6%96%B9%E6%B3%95/" style="font-size: 10px;">前向分步方法</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 10px;">动态规划</a> <a href="/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">原型模式</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 10px;">回溯</a> <a href="/tags/%E5%9B%A0%E7%89%B9%E7%BD%91%E5%8E%86%E5%8F%B2/" style="font-size: 10px;">因特网历史</a> <a href="/tags/%E5%9B%BE/" style="font-size: 10px;">图</a> <a href="/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/" style="font-size: 10px;">图算法</a> <a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 10px;">密码学</a> <a href="/tags/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">工厂方法模式</a> <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" style="font-size: 10px;">并查集</a> <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/" style="font-size: 10px;">微信小程序</a> <a href="/tags/%E6%84%9F%E7%9F%A5%E6%9C%BA/" style="font-size: 10px;">感知机</a> <a href="/tags/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/" style="font-size: 10px;">提升方法</a> <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">操作系统</a> <a href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 10px;">支持向量机</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 10px;">数据结构</a> <a href="/tags/%E6%95%B0%E8%AE%BA/" style="font-size: 10px;">数论</a> <a href="/tags/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" style="font-size: 10px;">最大熵模型</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/" style="font-size: 10px;">朴素贝叶斯算法</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 20px;">机器学习</a> <a href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" style="font-size: 10px;">极大似然估计</a> <a href="/tags/%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">模板方法模式</a> <a href="/tags/%E6%AF%95%E4%B8%9A/" style="font-size: 10px;">毕业</a> <a href="/tags/%E6%AF%95%E4%B8%9A%E6%97%85%E8%A1%8C/" style="font-size: 10px;">毕业旅行</a> <a href="/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" style="font-size: 15px;">离散数学</a> <a href="/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">策略模式</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 20px;">统计学习方法</a> <a href="/tags/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/" style="font-size: 10px;">装饰模式</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">计算机网络</a> <a href="/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" style="font-size: 10px;">设计原则</a> <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/" style="font-size: 10px;">贝叶斯估计</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/" style="font-size: 10px;">软件测试</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">逻辑斯谛回归</a> <a href="/tags/%E9%95%BF%E6%B2%99/" style="font-size: 10px;">长沙</a> <a href="/tags/%E9%9D%A2%E7%BB%8F/" style="font-size: 10px;">面经</a> <a href="/tags/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/" style="font-size: 10px;">高斯分布</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">十一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/11/29/public/webpushr-sw/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/29/public/newPost/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/06/30/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B/">《统计学习方法》读书笔记 · 隐马尔可夫模型</a>
          </li>
        
          <li>
            <a href="/2021/06/24/2021%E6%AF%95%E4%B8%9A%E7%A2%8E%E7%A2%8E%E5%BF%B5/">2021毕业碎碎念</a>
          </li>
        
          <li>
            <a href="/2021/06/24/%E6%AF%95%E4%B8%9A%E6%97%85%E8%A1%8C2021/">毕业旅行2021</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 xyy<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>